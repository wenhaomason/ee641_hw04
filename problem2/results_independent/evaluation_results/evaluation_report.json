{
  "performance": {
    "mean_reward": 10.665999999999999,
    "success_rate": 0.0,
    "avg_steps": 50.0,
    "rewards": [
      -4.999999999999998,
      93.7,
      47.49999999999998,
      -4.999999999999998,
      41.19999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      85.3,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      100.0,
      -4.999999999999998,
      -4.999999999999998,
      85.3,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      97.9,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998,
      89.5,
      -4.999999999999998,
      -4.999999999999998,
      97.9,
      -4.999999999999998,
      -4.999999999999998,
      -4.999999999999998
    ],
    "steps": [
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50,
      50
    ]
  },
  "communication": {
    "agent_A": {
      "mean": 0.6310063600540161,
      "std": 0.07371844351291656,
      "min": 0.5950692296028137,
      "max": 0.887255072593689
    },
    "agent_B": {
      "mean": 0.65743088722229,
      "std": 0.13032515347003937,
      "min": 0.5781143307685852,
      "max": 0.9531318545341492
    },
    "sample_count": 1000,
    "correlation": -0.19506434849794316
  },
  "generalization": {
    "mean_reward": 15.959999999999999,
    "success_rate": 0.01,
    "per_config": [
      {
        "mean_reward": 5.5,
        "success_rate": 0.0,
        "avg_steps": 50.0,
        "rewards": [
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          100.0,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998
        ],
        "steps": [
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      },
      {
        "mean_reward": 7.2,
        "success_rate": 0.1,
        "avg_steps": 45.2,
        "rewards": [
          -4.999999999999998,
          12.0,
          -4.999999999999998,
          -4.999999999999998,
          100.0,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998
        ],
        "steps": [
          50,
          2,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      },
      {
        "mean_reward": 15.580000000000002,
        "success_rate": 0.0,
        "avg_steps": 50.0,
        "rewards": [
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          95.8,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          100.0,
          -4.999999999999998
        ],
        "steps": [
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      },
      {
        "mean_reward": -4.999999999999998,
        "success_rate": 0.0,
        "avg_steps": 50.0,
        "rewards": [
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998
        ],
        "steps": [
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      },
      {
        "mean_reward": 14.319999999999999,
        "success_rate": 0.0,
        "avg_steps": 50.0,
        "rewards": [
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          100.0,
          -4.999999999999998,
          -4.999999999999998,
          83.2,
          -4.999999999999998,
          -4.999999999999998
        ],
        "steps": [
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      },
      {
        "mean_reward": 33.85,
        "success_rate": 0.0,
        "avg_steps": 50.0,
        "rewards": [
          -4.999999999999998,
          -4.999999999999998,
          87.4,
          -4.999999999999998,
          95.8,
          -4.999999999999998,
          91.6,
          -4.999999999999998,
          -4.999999999999998,
          93.7
        ],
        "steps": [
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      },
      {
        "mean_reward": 24.82,
        "success_rate": 0.0,
        "avg_steps": 50.0,
        "rewards": [
          -4.999999999999998,
          -4.999999999999998,
          91.6,
          -4.999999999999998,
          100.0,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          91.6
        ],
        "steps": [
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      },
      {
        "mean_reward": 25.869999999999997,
        "success_rate": 0.0,
        "avg_steps": 50.0,
        "rewards": [
          97.9,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          100.0,
          -4.999999999999998,
          -4.999999999999998,
          95.8,
          -4.999999999999998
        ],
        "steps": [
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      },
      {
        "mean_reward": 24.4,
        "success_rate": 0.0,
        "avg_steps": 50.0,
        "rewards": [
          -4.999999999999998,
          97.9,
          -4.999999999999998,
          97.9,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          83.2
        ],
        "steps": [
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      },
      {
        "mean_reward": 13.060000000000002,
        "success_rate": 0.0,
        "avg_steps": 50.0,
        "rewards": [
          87.4,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          83.2,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998,
          -4.999999999999998
        ],
        "steps": [
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50
        ]
      }
    ]
  },
  "trajectory_path": "/Users/wenhaos/ProjectMason/ee641/hw4-starter/problem2/results/evaluation_results/trajectories.png",
  "heatmap_path": "/Users/wenhaos/ProjectMason/ee641/hw4-starter/problem2/results/evaluation_results/communication_heatmap.png"
}